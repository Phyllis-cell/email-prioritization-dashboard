#  Email Prioritization System (Model + Dashboard)

This repository contains an end-to-end **email prioritization system** that classifies incoming emails into actionable priority levels and includes an interactive dashboard for testing and evaluation.

The project demonstrates **data preprocessing, rule-guided labeling, machine learning modeling, explainability, evaluation metrics, and deployment readiness**.

---

##  Problem Statement

Design a system that processes simulated email events using:
- **Sender (From)**
- **Subject**
- **Body**

and assigns one of the following priority labels:

- **Prioritize** ‚Äì critical or security-related emails (MFA, verification, password reset)
- **Default** ‚Äì general informational emails
- **Slow** ‚Äì promotional or non-urgent emails

Each prediction must include:
- Priority label
- Human-readable reasoning
- Confidence score

---

##  Solution Overview

### 1. Email Parsing
Raw email text is parsed into:
- `from`
- `subject`
- `body`

This ensures the model explicitly consumes realistic email signals rather than raw text only.

---

### 2. Priority Label Generation
Rule-based logic is used to generate training labels:
- Security keywords ‚Üí **Prioritize**
- Marketing keywords ‚Üí **Slow**
- Otherwise ‚Üí **Default**

These labels simulate realistic email prioritization behavior.

---

### 3. Text Preprocessing
A lightweight preprocessing pipeline is applied:
- Email header removal
- URL / EMAIL / NUM token preservation
- Text normalization (lowercasing, spacing)

This avoids over-cleaning while preserving intent.

---

### 4. Model
- **TF-IDF Vectorization** (unigrams + bigrams)
- **Logistic Regression**

Chosen for:
- Simplicity
- Interpretability
- Strong baseline performance for text classification

---

### 5. Explainability
Each prediction returns:
- **Label** ‚Äì predicted priority
- **Reasoning** ‚Äì pattern-based explanation
- **Confidence** ‚Äì model probability score

This ensures the system is not a black box.

---

##  Evaluation

Model evaluation includes:
- Accuracy
- Macro-F1 score
- Confusion matrix
- Classification report

These metrics are displayed both in code and in the dashboard UI.

---

##  Interactive Dashboard

The Gradio dashboard allows users to:
- Submit test email events (sender, subject, body)
- View predictions in real time
- Inspect model performance metrics

---

## üõ† Tech Stack

- Python
- scikit-learn
- pandas, numpy
- matplotlib
- Gradio

---

##  Repository Structure

```
.
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ email_classification_dataset.csv
‚îî‚îÄ‚îÄ README.md
```

---

##  Run Locally

```bash
pip install -r requirements.txt
python app.py
```

---

##  Deployment Note

The application is **deployment-ready** and can be hosted using:
- Hugging Face Spaces (Gradio)
- Any standard Python hosting environment

Deployment is optional depending on evaluation requirements.

---
# LINKS
Live App: https://huggingface.co/spaces/Phyllis10/email-prioritization-dashboard
Source Code: (your GitHub repo link)
Video Demo: (Loom link ‚Äî ‚Äúcoming soon‚Äù for now)


##  Author
**Phyllis Barikisu Snyper**  
Data Science Engineer & AI Lead
